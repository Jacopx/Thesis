% * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
% *                             Thesis                                *
% *                 https://github.com/Jacopx/Thesis                  *
% * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *

\documentclass[%
    corpo=12pt,
    twoside,
%    stile=classica,
    oldstyle,
    autoretitolo,
    greek,
    evenboxes,
%    tipotesi,
]{toptesi}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{listings}

\hypersetup{%
    pdfpagemode={UseOutlines},
    bookmarksopen,
    pdfstartview={FitH},
    colorlinks,
    linkcolor={blue},
    citecolor={blue},
    urlcolor={blue}
  }

%%%%%%% Definizioni locali
\newtheorem{osservazione}{Osservazione}% Standard LaTeX


\begin{document}

\ateneo{Politecnico di Torino}
%
% Non tutte le universit√† hanno un nome proprio
%\nomeateneo{Sede di Torre Elettra}
%
% \FacoltaDi{Faculty of Computer Engineering}% lo spazio finale correttamente sparisce

\titolo{Time  prediction of software development via machine learning}
\sottotitolo{Artificial Intelligence applied to Software Engineering}

%
%%%%%%% Corso degli studi
\corsodilaurea{Computer Engineering}% per la laurea
%\corsodidottorato{Meccanica}% per il dottorato

\renewcommand*\IDlabel{}
%
\candidato{Jacopo \textsc{Nasi} [255320]}

%%%%%%% Relatori o supervisori
\relatore{prof.~Maurizio Morisio}

%%%%%%% Tutore
\tutoreaziendale{dott.\ Davide Piagneri}
\NomeTutoreAziendale{Supervisore aziendale\\EisWORLD SRL}

\sedutadilaurea{\textsc{Anno~accademico} 2019-2020}


%%%%%%% Logo della sede
\logosede{polito}

%%%%%%% OFFSET
%\setbindingcorrection{3mm}

\english%  di default e' in vigore \italiano

\iflanguage{english}{%
	\retrofrontespizio{This work is subject to the Creative Commons Licence}
	\DottoratoIn{PhD Course in\space}
	\CorsoDiLaureaIn{Master degree course in\space}
	\NomeMonografia{Bachelor Degree Final Work}
	\TesiDiLaurea{Master Degree Thesis}
	\NomeDissertazione{PhD Dissertation}
	\InName{in}
	\CandidateName{Candidates}% or Candidate
	\AdvisorName{Supervisors}% or Supervisor
	\TutorName{Tutor}
	\NomeTutoreAziendale{Internship Tutor}
	\CycleName{cycle}
	\NomePrimoTomo{First volume}
	\NomeSecondoTomo{Second Volume}
	\NomeTerzoTomo{Third Volume}
	\NomeQuartoTomo{Fourth Volume}
	\logosede{polito}% or comma separated list of logos
}{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frontespizio

\summary

The software development is fundamental in the new world, how about using artificial intelligence to improve it.


\acknowledgements

Un ringraziamento speciale ai cavalieri di Smirnuff, luce della mia battaglia.

\indici

\mainmatter

% #######################################
% #            Introduction             #
% #######################################

\chapter{Introduction}
\label{chap:intro}
\section{General Problem}
Forecasting is one of the most critic part of a company, it could drive to easily success as well as drive to failure. A software project is not different from a manufacturing product, its development, infact, require analysis of different kind, from resources needed to costs and time required.\\
The software development experience shows that the process of analysis is really difficult, due to the nature of the problem, coding is a mind product and the time required to produce it can varying in accord to a lot of different factors.

\section{Tools used}
This work is mainly conducted using software tools, here a list of the tools used:

\paragraph{\href{https://www.python.org/}{Python}} The main programming language of the thesis project. Used for data management, feature extraction, machine learning models and for interfaction with other softwares. The specific version used is the v3.7.0

\paragraph{\href{https://pandas.pydata.org/}{Pandas}} Open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.

\paragraph{\href{https://numpy.org/}{NumPy}} Scientific computing with Python.

\paragraph{\href{https://matplotlib.org/}{Matplotlib}} 2D Plotting library for Python.

\paragraph{\href{https://seaborn.pydata.org/}{Seaborn}} Another plotting library for Python.

\paragraph{\href{https://www.tensorflow.org/}{Tensorflow}} Platform for machine learning.

\paragraph{\href{https://keras.io/}{Keras}} High level API for neural networks.

\paragraph{\href{https://scikit-learn.org/stable/}{SciKit-Learn}} Tools and libraries for machine learning.

\paragraph{\href{https://gitlab.com}{GitLab}} Sourcing platform based on Git. Used for the code of the project, available here:\\
\url{https://gitlab.com/EiS-Projects/analytics/temp/thesisProjectJN}.

\paragraph{\href{https://github.com}{GitHub}} Sourcing platform based on Git. Used for the thesis and calendar sourcing:
\begin{itemize}
  \item Thesis: \url{https://github.com/Jacopx/Thesis}
  \item Calendar: \url{https://github.com/Jacopx/ThesisCalendar}
\end{itemize}

\paragraph{\href{https://www.jetbrains.com/}{JetBrains IDEs}} Student-free IDE for different language development, product used:
\begin{itemize}
  \item PyCharm: \url{https://www.jetbrains.com/pycharm/}
  \item DataGrip: \url{https://www.jetbrains.com/datagrip/}
\end{itemize}

% #######################################
% #            State of art             #
% #######################################
\chapter{State of art}
\section{Related works}
Speaking about other works.

% #######################################
% #              Datasets               #
% #######################################

\chapter{Datasets}
\label{chap:dataset}
The following section illustrate the structure of the all the principal datasets used during this thesis project.
\section{SEOSS33}
The SEOSS33\cite{SEOSS33} is a \href{https://doi.org/10.7910/DVN/PDDZ4Q}{dataset} collecting bug, issue, reports, commit and lot of other information of 33 open source project, following their progress via sourcing platform. The dataset is enriched also with time stamps, release versions, component information and developer comments.\\
At today there are no other public research conducted over this datasets, this works seems to be first.\\
The data is retrived by the issue tracking system (ITS) and the version control system (VCS).
To unify the project specific difference, the typed issue, e.g. \textit{New Feature} or \textit{Bug Report}, are mapped to five issue categories:
\begin{itemize}
  \item Bug: A problem which impairs or prevents the functions of the product
  \item Feature: A new feature of the product
  \item Improvement: An enhancement to an existing feature
  \item Task: A task that needs to be done
  \item Other: Various
\end{itemize}

The study collects 33 projects that are using Atalassian Jira and git, for popularity reasons. Is also required that the projects in the dataset should be majorly written in one programming language, Java is choosen. Due to machine learning nature, the choosen project must have great number of issue, all project were in development for at least three years. Among these products we have selected five of them, because of size, as shown in table \ref{tab:seoss33_selected}:

\begin{center}
  \captionof{table}{Project data distribution} \label{tab:seoss33_selected}
  \begin{tabular}{ |c|c|c| }
     \hline
     \textbf{Project} & \textbf{Month} & \textbf{Issue} \\
     \hline
     \hline
     Hadoop & 150 & $39086$ \\
     Hbase & 131 & $19247$ \\
     Maven & 183 & $18025$ \\
     Cassandra & 106 & $13965$ \\
     Hive & 113 & $18025$ \\
     \hline
  \end{tabular}
\end{center}

More selection charactheristics can be found in chapter 2.1 \cite{SEOSS33}.\\
Is fundamental to understand the structure of this dataset, the majority of the forecasting operation tests are conducted using the data stored by this research.\\
Each project is stored in a SQLITE file, a SQL offline database, the structure is based on the entity of the \textit{issue}, identified by an \textit{issue\_id}, the other tables are used to link additional information, like the number of commit, the version referred, comments and others features. The figure \ref{fig:seoss33_db} show the database schema.

\begin{figure}[!h]
  \includegraphics[width=\linewidth]{figure/seoss33_db_schema.png}
  \caption{SEOSS33 data model}
  \label{fig:seoss33_db}
\end{figure}

Each table contains different types of data that will be used to generate the data used to forecast.

% #######################################
% #          Machine Learning           #
% #######################################

\chapter{Machine Learning}
\label{chap:ml}
\section{Introduction}
Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. The word ML is almost in the public domain now, in the last decades the usage of these kind of algorithms has drammatically raisen although most of it had already been developed for years. The main reason is the increase in the computational capacity of the systems.\\
There are two types of systems:
\begin{itemize}
  \item Knowledge-based: Acquisition and modeling of common-sense knowledge and expert knowledge (from rules to facts)
  \item Learning: Extraction of knowledge and rules from example/experience (from facts to rules)
\end{itemize}
All the machine learning techniques try to develop systems similar to the second definitions. ML algorithms can be divided in three categories: supervised, unsupervised and reinforcement learning. The first will be used to predict class based on previous knowledge, the second tries to labeling data without a priori experience and the third bases its learning on action reward.\\
There a lot of different models available, the following chapters will focus on the models used in this project.

\paragraph{Supervised Learning}
is a powerful technique to process labeled, which is a dataset with that has been classified, to infer a learning algorithm. These dataset is used as basis to predict, and learn how, unlabeled data. There are two types of supervised learning, classification and linear regression. The goal of classification models is to predict categorical class labels of new instances, based on a training set of past observations. The classification can be binary or multi-class. Instead, regression, aim to predict continuos outcome, it tries to find mathematical relationships between variables to predict the target with a reasonable level of approximation. Our project is only focused on regression, classification will not be further discussed.

\section{Ensable Methods}
All the supervised learning method used are based on ensable, the basic idea is to merge multiple, different, hypotesis in order to improved the quality of the prediction, for example the random forest or gradient boosting are ensable of multiple decision trees. The following paragraphs will deal with the models used specifically.

\paragraph{Random Forest}
Random Forest (RF) is a supervised learning algorithm which uses ensable learning method for classification and regression. They are built by combining the predictions of several trees, each of which is trained independently and the prediction of the trees are combined through averaging \cite{RF_theory}. A visualization of a RF is shown in figure \ref{fig:rf}.\\
\begin{figure}[!h]
  \includegraphics[width=\linewidth]{figure/rf.png}
  \caption{Random Forest simplified scheme \cite{rf}}
  \label{fig:rf}
\end{figure}
Three parameters are important defining the RF, (1) the methods for splitting the leafs, (2) the type of predictor to use in each leaf, and (3) the method for injecting randomness.
Splitting of require the selection of shape and a method for evaluating the quality of each candidate. Typical choices are axis aligned splits, where data is routed to sub-tree depending on a threshold. The threshold can be chosen randomly of by a leafs optimization function. After the generation of different candidate splits a choosing criterion must be defined in order to split the leaf. One of the simplest strategy is to choose among the candidates uniformly at random, otherwise is possible to select the candidate split which optimize a purity function (information gain for example) over the leaf that would be created.
The most common predictors, for each leaf, is the average response over training points which fall in that leaf.
The injection of randomness can happen in different ways, the size of candidate splits, coefficients for random combinations, etc... In any case the thresholds can be also defined randomly or by optimization over data. Another solution is build tree using bootstrapped or sub-sampled dataset.\\
The training phase is performed independently by each tree by exploiting an assignement in structure and estimation points to respectively change the shape of the tree and to improve the estimator fit.\\
Once the forest has been trained it can be used to make predictions for unlabeled data points. In the prediction phase, each single tree, independently make its own prediction than an average of all the trees is computed to make a single outcome value. The contribution of each tree to the final value is the same.\\
Out implementation use Random Forest developed by SciKit-Learn v0.21:
\begin{lstlisting}[language=python, frame=single]
  from sklearn.ensemble import RandomForestRegressor
\end{lstlisting}
The specific parameters of the model will be explained during the \autoref{chap:forecasting} about forecasting.
% To make predictions for a query point $x$, each tree independently predicts
% \begin{center}
%   \begin{equation}
%     f^{j}_{n}(x) = \frac{1}{N^{e}(A_{n}(x))} \sum_{I_{i}=e}^{Yi \in A_{n}(x)} Y_{i}
%   \end{equation}
% \end{center}
% and the forest averages the prediction of each tree
% \begin{center}
%   \begin{equation}
%     f^{(M)}_{n}(x) = \frac{1}{M} \sum_{j=1}^{M} f^{j}_{n}(x)
%   \end{equation}
% \end{center}

\paragraph{Gradient Boosting Machines}
Gradient Boosting Machines (GBM) are a family of powerful machine learning techniques that have shown considerable success in a wide range of pratical application. They are higly customizable to the particular needs of the application, line being learned with respect to different loss functions \cite{gbm}. Techniques like RF rely on simple averaging of model in the ensable. The family of boosting methods is based on a different constructive strategy of ensemble formation. Boosting add, sequentially, new models to the ensable. In GBM the learning phase consecutively fits new models to improve the accuracy of the estimations. Ideally they construct new basic layers,  decision trees of fixed size, to be maximally correlated with the negative gradient of the loss function of the ensable. The loss function should be chosen by the developer, even ad-hoc loss function could be implemented. The attempt is to solve this minimization problem numerically via steepest descent \cite{ensable}.\\
This high flexibility of GBM makes them really customizable to any kind of task. Given its simplicity a lot of experimentation can be performed over the model.\\
Our project implement Gradient Boosting Decision Tree (GBDT) developed by SciKit-Learn v0.21:
\begin{lstlisting}[language=Python, frame=single]
  from sklearn.ensemble import GradientBoostingRegressor
\end{lstlisting}

\section{Neural Networks}
A Neural Network (NN) is a machine learning approach inspired by the way in which the brain performs a particular learning task, network of simple computational units (neuros) connected by links (synapses). The knowledge about the learning task is given in the form of training examples, the inter neuros connection strengths (weights) are used to store the acquired information. During the learning process the weights are modified in order to model the particular learning task correctly on the examples.\\
The learning phase can be both supervised or unsupervised. Supervised is used for pattern recognition, regression and similar, is trained using data with both input and desired output. Unsupervised instead is mainly used for clustering and the learning is made using unlabeled training examples. Only supervised one will be evaluated.\\
There are three main classes of network architectures:
\begin{itemize}
  \item Single-layer feed-forward
  \item Multi-layer feed-forward
  \item Recurrent
\end{itemize}
A standard architecture is composed of three different layers, \textit{input units}, \textit{hidden units} and \textit{output units}, all the layers are linked with the learning algorithms used to train. An example of a complete multi-layer network in \ref{fig:mlff}.

\begin{figure}[!h]
  \includegraphics[width=\linewidth]{figure/feed_foward.png}
  \caption{Multi-layer feed-forward NN}
  \label{fig:mlff}
\end{figure}

The neuron is the basic processing unit of the network, which received the inputs. Each input is cobined with its internal state and an optional activation function, it  produce an output value that will be passed to the next layers. The weights, defined during the training phase, correspond to the importance of the connection. The different inputs are summed using a weighted sum:
\begin{center}
  \begin{equation}
    u = \sum^{m}_{j=1} w_{j}x_{j}
  \end{equation}
\end{center}
The computed value is than scaled using an activation function $\varphi$ for limiting the amplitude of the output of the neuron by applying the function:
\begin{center}
  \begin{equation}
    y = \varphi(u + b)
  \end{equation}
\end{center}
Where $b$ represent the bias an external parameter of the neuron, $y$ represent than the output value for the next level. An example of the structure can be found in figure \ref{fig:neuron}

\begin{figure}[!h]
  \includegraphics[width=\linewidth]{figure/neuron.png}
  \caption{Neruon view}
  \label{fig:neuron}
\end{figure}

There are several different functions that can be used to activate the neurons, they are trying to emulate the typical response of a biological neuron and its different activation methods. The most common are: linear, step, sign, relu and sigmoid.\\


% \paragraph{Recurrent Neural Networks}
% Recurrent Neural Networks (RNN) is a class of NN that keep connections between nodes and a temporal sequence. The main difference, respect NN, is that has feedback connections, this memory allow to keep track of temporal dynamic behaviour, they can process single data point or entire sequence of data, like video or speech.
%
% \paragraph{Long-Short Term Memory}
% One of the most used type of RNN is the Long-Short Term Memory (LSTM), were developed to solve the problems of exploding and vanishing of gradient typical of normal RNN.

% \section{Evaluation metrics}
% MISSING



% #######################################
% #             Forecasting             #
% #######################################

\chapter{Forecasting}
\label{chap:forecasting}
\section{Introduction}
Forecasting is the process of making predictions of future based on past and present data by trends analysis. Forecasting is one of the most desired machine learning functionality, it could be used to improve each kind of process, from finacials to production ones. Of course this task is not easy to achieve, a lot of resources and studies are needed to accomplish it.
The software development is identical to a product development process, starts from the ideation and ends with the production itself.
The goal is to predict the defectiveness in order to efficently allocate the development effort.

\section{Features}
The main advantage, in data analysis, of machines is that they can compute a lot of different data and finding a lot of patterns and correlation that human can't find. Combine the human attitude of logical correlations and machines capacity of number analysis can drive to a powerful combination that can drastically improve the forecasting ability.
Each artificial intelligence algorithms require a correct and properly studied data in order to perform a valuable prediction, one of the basic step is the data preparation, providing correct and organized data is fundamental to correctly fit the network over the problem.

% \section{Models detail}
% \section{One-Shot Prediction}
% \section{Recurrent forecasting}
% \section{Results}


% % #######################################
% % #         Model abstraction           #
% % #######################################
%
% \chapter{Model abstraction}
% % \section{CommonDB}
% \section{SFBS and literature comparisons}
% \section{SFFD}


% #######################################
% #             Conclusion              #
% #######################################

\chapter{Conclusion}



% #######################################
% #            BIBLIOGRAPHY             #
% #######################################
\bibliography{biblio}
\bibliographystyle{QUICKtran}

\end{document}
